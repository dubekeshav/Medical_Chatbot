{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "# Just to check if the environment is working or not\n",
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Medical_Chatbot\\\\Medical_Chatbot\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the path\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Medical_Chatbot\\\\Medical_Chatbot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will change the directory to stay in tthe root folder, which will make things easier\n",
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to process the pdf files, importing the PDF Loader, Directory Loader, and also, a text splitter to convert the text into smaller chunks\n",
    "# %pip install langchain\n",
    "# %pip install -U langchain-community\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pdf files\n",
    "def load_pdf_files(data_directory):\n",
    "    # Loading all the files having a .pdf extension\n",
    "    pdf_loader = DirectoryLoader(data_directory, glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "    documents = pdf_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Using cached pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install pypdf\n",
    "\n",
    "extracted_data = load_pdf_files('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 0, 'page_label': 'i'}, page_content=''),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 1, 'page_label': 'ii'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 2, 'page_label': 'iii-1'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n1\\nA-B\\nJACQUELINE L. LONGE, PROJECT EDITOR'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 3, 'page_label': 'iii-2'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n2\\nC-F\\nJACQUELINE L. LONGE, PROJECT EDITOR'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 4, 'page_label': 'iii-3'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n3\\nG-M\\nJACQUELINE L. LONGE, PROJECT EDITOR'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 5, 'page_label': 'iii-4'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n4\\nN-S\\nJACQUELINE L. LONGE, PROJECT EDITOR'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 6, 'page_label': 'iii-5'}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION\\nVOLUME\\n\\x81\\n5\\nT-Z\\nORGANIZATIONS\\nGENERAL INDEX\\nJACQUELINE L. LONGE, PROJECT EDITOR'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 7, 'page_label': 'iv'}, page_content='THE GALE ENCYCLOPEDIA OF MEDICINE, THIRD EDITION\\nª 2006 Thomson Gale, a part of The Thomson\\nCorporation.\\nThomson and Star Logo are trademarks and\\nGale is a registered trademark used herein\\nunder license.\\nFor more information, contact\\nThe Gale Group, Inc.\\n27500 Drake Rd.\\nFarmington Hills, MI 48331-3535\\nOr you can visit our Internet site at\\nhttp://www.gale.com\\nALL RIGHTS RESERVED\\nNo part of this work covered by the copyright\\nhereon may be reproduced or used in any\\nform or by any means—graphic, electronic, or\\nmechanical, including photocopying, record-\\ning, taping, Web distribution, or information\\nstorage retrieval systems—without the written\\npermission of the publisher.\\nThis publication is a creative work fully pro-\\ntected by all applicable copyright laws, as well\\nas by misappropriation, trade secret, unfair\\ncondition, and other applicable laws. The\\nauthors and editors of this work have added\\nvalue to the underlying factual material herein\\nthrough one or more of the following: coordi-\\nnation, expression, arrangement, and classifi-\\ncation of the information.\\nFor permission to use material from this pro-\\nduct, submit your request via the web at http://\\nwww.gale-edit.com/permission or you may\\ndownload our Permissions Request form and\\nsubmit your request by fax of mail to:\\nPermissions\\nThomson Gale\\n27500 Drake Rd.\\nFarmington Hills, MI 48331-3535\\nPermissions Hotline:\\n248-699-8006 or 800-877-4253, ext. 8006\\nFax: 248-699-8074 or 800-762-4058\\nSince this page cannot legibly accommodate all\\ncopyright notices, the acknowledgments con-\\nstitute an extension of the copyright notice.\\nWhile every effort has been made to ensure\\nthe reliability of the information presented in\\nthis publication, Thomson Gale does not\\nguarantee the accuracy of the data contained\\nherein. Thomson Gale accepts no payment for\\nlisting; and inclusion in the publication of any\\norganization, agency, institution, publication,\\nservice, or individual does not imply endorse-\\nment of the editors or publisher. Errors brought\\nto the attention of the publisher and verified to\\nthe satisfaction of the publisher will be cor-\\nrected in future editions.\\nLIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA\\nThe Gale encyclopedia of medicine / Jacqueline L. Longe, editor.– 3rd ed.\\np. ; cm.\\nIncludes bibliographical references and index.\\nISBN 1-4144-0368-2 (set hardcover : alk. paper) – ISBN 1-4144-0369-0 (v. 1 : hardcover\\n: alk. paper) – ISBN 1-4144-0370-4 (v. 2 : hardcover : alk. paper) – ISBN 1-4144-0371-2\\nv. 3 : hardcover : alk. paper) – ISBN 1-4144-0372-0 (v. 4 : hardcover : alk. paper) –\\nISBN 1-4144-0373-9 (v. 5 : hardcover : alk. paper)\\n1. Internal medicine–Encyclopedias.\\n[DNLM: 1. Internal Medicine–Encyclopedias–English. 2. Complementary Therapies–\\nEncyclopedias–English. WB 13 G151 2005] I. Title: Encyclopedia of medicine. II. Longe,\\nJacqueline L. III. Gale Group.\\nRC41.G35 2006\\n616’.003–dc22\\n2005011418\\nThis title is also available as an e-book\\nISBN 1-4144-0485-9 (set)\\nContact your Gale sales representative for ordering information.\\nISBN 1-4144-0368-2 (set)\\n1-4144-0369-0 (Vol. 1)\\n1-4144-0370-4 (Vol. 2)\\n1-4144-0371-2 (Vol. 3)\\n1-4144-0372-0 (Vol. 4)\\n1-4144-0373-9 (Vol. 5)\\nPrinted in China\\n1 0987654321\\nProject Editor\\nJacqueline L. Longe\\nEditorial\\nShirelle Phelps, Laurie Fundukian, Jeffrey\\nLehman, Brigham Narins\\nEditorial Support Services\\nLuann Brennan, Grant Eldridge, Andrea Lopeman\\nRights Acquisition Management\\nShalice Caldwell-Shah\\nImaging\\nRandy Bassett, Lezlie Light, Dan Newell,\\nChristine O’Bryan, Robyn V. Young\\nProduct Design\\nTracey Rowens\\nComposition and Electronic Prepress\\nEvi Seoud, Mary Beth Trimper\\nManufacturing\\nWendy Blurton, Dorothy Maki\\nIndexing\\nFactiva'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 8, 'page_label': 'v'}, page_content='CONTENTS\\nList of Entries............................................ vii\\nIntroduction.............................................. xxi\\nAdvisory Board....................................... xxiii\\nContributors ............................................ xxv\\nEntries\\nVolume 1: A-B............................................ 1\\nVolume 2: C-F......................................... 693\\nVolume 3: G-M...................................... 1533\\nVolume 4: N-S....................................... 2569\\nVolume 5: T-Z....................................... 3621\\nOrganizations......................................... 4037\\nGeneral Index........................................ 4061\\nGALE ENCYCLOPEDIA OF MEDICINE V'),\n",
       " Document(metadata={'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'creator': 'Adobe Acrobat 6.0', 'creationdate': '2006-10-16T20:19:33+02:00', 'moddate': '2016-02-07T11:23:03+07:00', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505, 'page': 9, 'page_label': 'vii'}, page_content='LIST OF ENTRIES\\nA\\nAbdominal ultrasound\\nAbdominal wall defects\\nAbortion, partial birth\\nAbortion, selective\\nAbortion, therapeutic\\nAbscess incision & drainage\\nAbscess\\nAbuse\\nAcetaminophen\\nAchalasia\\nAchondroplasia\\nAcid phosphatase test\\nAcne\\nAcoustic neuroma\\nAcrocyanosis\\nAcromegaly and gigantism\\nActinomycosis\\nAcupressure\\nAcupuncture\\nAcute kidney failure\\nAcute lymphangitis\\nAcute poststreptococcal\\nglomerulonephritis\\nAcute stress disorder\\nAddiction\\nAddison’s disease\\nAdenoid hyperplasia\\nAdenovirus infections\\nAdhesions\\nAdjustment disorders\\nAdrenal gland cancer\\nAdrenal gland scan\\nAdrenal virilism\\nAdrenalectomy\\nAdrenocorticotropic hormone test\\nAdrenoleukodystrophy\\nAdult respiratory distress syndrome\\nAging\\nAgoraphobia\\nAIDS tests\\nAIDS\\nAlanine aminotransferase test\\nAlbinism\\nAlcoholism\\nAlcohol-related neurologic disease\\nAldolase test\\nAldosterone assay\\nAlemtuzumab\\nAlexander technique\\nAlkaline phosphatase test\\nAllergic bronchopulmonary\\naspergillosis\\nAllergic purpura\\nAllergic rhinitis\\nAllergies\\nAllergy tests\\nAlopecia\\nAlpha1-adrenergic blockers\\nAlpha-fetoprotein test\\nAlport syndrome\\nAltitude sickness\\nAlzheimer’s disease\\nAmblyopia\\nAmebiasis\\nAmenorrhea\\nAmino acid disorders screening\\nAminoglycosides\\nAmnesia\\nAmniocentesis\\nAmputation\\nAmylase tests\\nAmyloidosis\\nAmyotrophic lateral sclerosis\\nAnabolic steroid use\\nAnaerobic infections\\nAnal atresia\\nAnal cancer\\nAnal warts\\nAnalgesics, opioid\\nAnalgesics\\nAnaphylaxis\\nAnemias\\nAnesthesia, general\\nAnesthesia, local\\nAneurysmectomy\\nAngina\\nAngiography\\nAngioplasty\\nAngiotensin-converting enzyme\\ninhibitors\\nAngiotensin-converting enzyme\\ntest\\nAnimal bite infections\\nAnkylosing spondylitis\\nAnorectal disorders\\nAnorexia nervosa\\nAnoscopy\\nAnosmia\\nAnoxia\\nAntacids\\nAntenatal testing\\nAntepartum testing\\nAnthrax\\nAntiacne drugs\\nAntiandrogen drugs\\nAntianemia drugs\\nAntiangina drugs\\nAntiangiogenic therapy\\nAntianxiety drugs\\nAntiarrhythmic drugs\\nAntiasthmatic drugs\\nAntibiotic-associated colitis\\nAntibiotics, ophthalmic\\nAntibiotics, topical\\nAntibiotics\\nAnticancer drugs\\nAnticoagulant and antiplatelet\\ndrugs\\nAnticonvulsant drugs\\nAntidepressant drugs, SSRI\\nGALE ENCYCLOPEDIA OF MEDICINE vii')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the data\n",
    "extracted_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's split the data into smaller chunks\n",
    "def split_data(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    data_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return data_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data chunks: 39994\n"
     ]
    }
   ],
   "source": [
    "data_chunks = split_data(extracted_data)\n",
    "print(f'Length of the data chunks: {len(data_chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to generate embeddings of the data chunks. So, for that, we will download an Embeddings model form Hugging Face\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE :: In Pinecone VectorDB, while creating the indexes, we need to specify the dimensions of our embeddings vector. So, make sure that you check the output dimensions of whichever model you use while creating embeddings.\n",
    "\n",
    "For example, the model that we are using to create embeddings, outputs a 384 dimensional dense vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/204.1 MB 15.1 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 10.2/204.1 MB 27.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 14.4/204.1 MB 24.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 18.1/204.1 MB 22.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 22.5/204.1 MB 22.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 26.5/204.1 MB 21.4 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 30.4/204.1 MB 21.3 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 34.3/204.1 MB 20.9 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 38.0/204.1 MB 20.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 41.9/204.1 MB 20.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 44.3/204.1 MB 19.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 49.8/204.1 MB 20.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 54.3/204.1 MB 20.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 58.5/204.1 MB 20.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 62.4/204.1 MB 20.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 66.3/204.1 MB 20.0 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 70.3/204.1 MB 19.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 74.4/204.1 MB 19.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 78.4/204.1 MB 19.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 82.1/204.1 MB 19.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 86.5/204.1 MB 19.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 90.7/204.1 MB 19.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 94.4/204.1 MB 19.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 98.6/204.1 MB 19.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 102.5/204.1 MB 19.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 106.4/204.1 MB 19.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 110.4/204.1 MB 19.6 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 114.3/204.1 MB 19.6 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 118.2/204.1 MB 19.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.4/204.1 MB 19.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.6/204.1 MB 19.6 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 130.5/204.1 MB 19.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 134.5/204.1 MB 19.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 138.4/204.1 MB 19.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 142.3/204.1 MB 19.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 146.5/204.1 MB 19.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 149.7/204.1 MB 19.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 151.5/204.1 MB 19.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 155.2/204.1 MB 19.0 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.5/204.1 MB 19.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 166.5/204.1 MB 19.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 170.9/204.1 MB 19.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.1/204.1 MB 19.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.0/204.1 MB 19.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 183.0/204.1 MB 19.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.9/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.1/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.8/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.0/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 18.4 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Downloading pillow-11.1.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 22.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.1 MB 39.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 24.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/41.0 MB 15.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.3/41.0 MB 15.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.7/41.0 MB 15.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.4/41.0 MB 15.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 16.5/41.0 MB 15.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.9/41.0 MB 14.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.5/41.0 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.1/41.0 MB 14.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.6/41.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.0/41.0 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.3/41.0 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.4/41.0 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.4/41.0 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.5/41.0 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 12.4 MB/s eta 0:00:00\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Using cached safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, Pillow, networkx, MarkupSafe, joblib, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.1 jinja2-3.1.5 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harry\\miniconda3\\envs\\medical_chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\harry\\miniconda3\\envs\\medical_chatbot\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\harry\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers\n",
    "\n",
    "embeddings_model = download_embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07155238837003708,\n",
       " 0.06848026812076569,\n",
       " 0.006603332236409187,\n",
       " 0.10176961123943329,\n",
       " 0.011122291907668114,\n",
       " 0.0002454034110996872,\n",
       " 0.016586650162935257,\n",
       " -0.01200536172837019,\n",
       " 0.042088884860277176,\n",
       " 0.04414103180170059,\n",
       " 0.10785843431949615,\n",
       " -0.068990558385849,\n",
       " -0.0043989988043904305,\n",
       " 0.03352139890193939,\n",
       " 0.017190447077155113,\n",
       " -0.032950084656476974,\n",
       " 0.030634544789791107,\n",
       " -0.045996662229299545,\n",
       " -0.0532722994685173,\n",
       " 0.04025152325630188,\n",
       " 0.04043767228722572,\n",
       " 0.03767035901546478,\n",
       " -0.017523281276226044,\n",
       " 0.01689179614186287,\n",
       " 0.007484895177185535,\n",
       " 0.01625249721109867,\n",
       " -0.05224785953760147,\n",
       " 0.0004039568593725562,\n",
       " 0.07939945161342621,\n",
       " -0.014782295562326908,\n",
       " -0.05030818283557892,\n",
       " 0.0027368483133614063,\n",
       " 0.05599784478545189,\n",
       " 0.06447503715753555,\n",
       " 0.019931472837924957,\n",
       " -0.0033759516663849354,\n",
       " 0.042722590267658234,\n",
       " 0.024140695109963417,\n",
       " 0.009568808600306511,\n",
       " 0.01153769064694643,\n",
       " -0.0006791026680730283,\n",
       " -0.12333039939403534,\n",
       " 0.014848548918962479,\n",
       " 0.017071988433599472,\n",
       " 0.017731836065649986,\n",
       " 0.007266833446919918,\n",
       " -0.037039585411548615,\n",
       " 0.017995992675423622,\n",
       " 0.0022986740805208683,\n",
       " -0.026694992557168007,\n",
       " -0.054305460304021835,\n",
       " -0.06786768138408661,\n",
       " -0.0741308256983757,\n",
       " -0.04626381769776344,\n",
       " 0.006802679039537907,\n",
       " 0.02663487382233143,\n",
       " 0.02509368769824505,\n",
       " 0.023989573121070862,\n",
       " 0.04677315056324005,\n",
       " 0.03525977209210396,\n",
       " -0.008635939098894596,\n",
       " -0.02247181534767151,\n",
       " -0.08282182365655899,\n",
       " 0.048395827412605286,\n",
       " 0.15006674826145172,\n",
       " 0.01711355336010456,\n",
       " -0.0408979170024395,\n",
       " -0.10597144067287445,\n",
       " -0.046109888702631,\n",
       " 0.016185158863663673,\n",
       " 0.02240215614438057,\n",
       " 0.03618002310395241,\n",
       " 0.02998211607336998,\n",
       " 0.022527558729052544,\n",
       " -0.003833686001598835,\n",
       " -0.014463764615356922,\n",
       " -0.017492398619651794,\n",
       " -0.10582008957862854,\n",
       " 0.11173780262470245,\n",
       " 0.04764087498188019,\n",
       " -0.07723522186279297,\n",
       " -0.10473693907260895,\n",
       " -0.019583452492952347,\n",
       " 0.04938649758696556,\n",
       " 0.004015690181404352,\n",
       " -0.02480868250131607,\n",
       " 0.09097010642290115,\n",
       " -0.07297533005475998,\n",
       " -0.09743816405534744,\n",
       " 0.01079378742724657,\n",
       " -0.003663727082312107,\n",
       " -0.021498210728168488,\n",
       " -0.011078044772148132,\n",
       " 0.01609397679567337,\n",
       " -0.039342865347862244,\n",
       " -0.013024919666349888,\n",
       " -0.07390706241130829,\n",
       " -0.020045073702931404,\n",
       " 0.006758301984518766,\n",
       " 0.08358971029520035,\n",
       " 0.012483065016567707,\n",
       " 0.03432689979672432,\n",
       " 0.02307959459722042,\n",
       " 0.040901780128479004,\n",
       " -0.10025639832019806,\n",
       " -0.08402780443429947,\n",
       " 0.019834749400615692,\n",
       " -0.058571599423885345,\n",
       " 0.02871432900428772,\n",
       " -0.0020598815754055977,\n",
       " -0.02334972470998764,\n",
       " -0.009011991322040558,\n",
       " 0.06320863962173462,\n",
       " 0.03496648371219635,\n",
       " -0.0201371181756258,\n",
       " -0.018847934901714325,\n",
       " -0.13730797171592712,\n",
       " 0.03648582100868225,\n",
       " -0.03378020599484444,\n",
       " 0.0339825265109539,\n",
       " 0.062279053032398224,\n",
       " 0.06824135780334473,\n",
       " -0.03842240571975708,\n",
       " -0.0022185787092894316,\n",
       " -0.06441249698400497,\n",
       " -0.058685433119535446,\n",
       " 0.06612559407949448,\n",
       " -6.338468312409291e-33,\n",
       " -0.019371166825294495,\n",
       " -0.06967859715223312,\n",
       " 0.028766129165887833,\n",
       " 0.06640766561031342,\n",
       " 0.008350269868969917,\n",
       " -0.0036329131107777357,\n",
       " -0.006086348555982113,\n",
       " 0.07392111420631409,\n",
       " -0.03414284065365791,\n",
       " -0.020717239007353783,\n",
       " -0.01582443155348301,\n",
       " -0.09003767371177673,\n",
       " 0.019865721464157104,\n",
       " 0.045528754591941833,\n",
       " 0.08235280960798264,\n",
       " 0.09847912937402725,\n",
       " -0.07028262317180634,\n",
       " 0.06829924881458282,\n",
       " -0.047240663319826126,\n",
       " 0.0611901618540287,\n",
       " -0.01705186255276203,\n",
       " 0.011153043247759342,\n",
       " -0.015623991377651691,\n",
       " -0.09049280732870102,\n",
       " -0.09797560423612595,\n",
       " -0.09817624092102051,\n",
       " 0.0034200483933091164,\n",
       " -0.004186797421425581,\n",
       " -0.05070698633790016,\n",
       " 0.024717509746551514,\n",
       " -0.003304332261905074,\n",
       " 0.011732370592653751,\n",
       " -0.05360597372055054,\n",
       " 0.06190382316708565,\n",
       " 0.016143469139933586,\n",
       " 0.0254643764346838,\n",
       " 0.04266691580414772,\n",
       " -0.06828094273805618,\n",
       " -0.01373451016843319,\n",
       " 0.022351566702127457,\n",
       " -0.059370964765548706,\n",
       " -0.027075087651610374,\n",
       " -0.00018808139429893345,\n",
       " 0.007983575575053692,\n",
       " 0.0953863337635994,\n",
       " 0.0030078119598329067,\n",
       " -0.028372399508953094,\n",
       " -0.022013945505023003,\n",
       " 0.0013016853481531143,\n",
       " 0.02584284357726574,\n",
       " -0.015799863263964653,\n",
       " 0.03806336596608162,\n",
       " 0.033162157982587814,\n",
       " -0.024053210392594337,\n",
       " 0.03933344781398773,\n",
       " 0.07334218919277191,\n",
       " 0.046724140644073486,\n",
       " 0.006004572380334139,\n",
       " -0.034967806190252304,\n",
       " 0.061555907130241394,\n",
       " 0.014883660711348057,\n",
       " 0.04606161639094353,\n",
       " -0.06237233430147171,\n",
       " 0.06746379286050797,\n",
       " 0.006267935503274202,\n",
       " 0.018433839082717896,\n",
       " -0.03269054368138313,\n",
       " -0.06622753292322159,\n",
       " 0.07579828798770905,\n",
       " 0.030778883025050163,\n",
       " -0.04010999575257301,\n",
       " -0.0601886510848999,\n",
       " -0.03443295508623123,\n",
       " 0.07230904698371887,\n",
       " -0.01300307922065258,\n",
       " -0.06293561309576035,\n",
       " 0.02421119064092636,\n",
       " 0.05188354104757309,\n",
       " -0.007939564064145088,\n",
       " -0.0006405580788850784,\n",
       " 0.039729293435811996,\n",
       " -0.11139818280935287,\n",
       " 0.025296058505773544,\n",
       " -0.029827166348695755,\n",
       " -0.09181874990463257,\n",
       " -0.009372005239129066,\n",
       " -0.016190974041819572,\n",
       " -0.09458926320075989,\n",
       " 0.026556655764579773,\n",
       " -0.007073677144944668,\n",
       " -0.0032149360049515963,\n",
       " 0.0023885644041001797,\n",
       " 0.04131553694605827,\n",
       " -0.030786976218223572,\n",
       " 0.05999129265546799,\n",
       " 2.930132544104646e-33,\n",
       " -0.056367892771959305,\n",
       " 0.0891282707452774,\n",
       " -0.07457434386014938,\n",
       " 0.06699755787849426,\n",
       " 0.08118267357349396,\n",
       " -0.030013272538781166,\n",
       " 0.08066224306821823,\n",
       " -0.04701190069317818,\n",
       " -0.04885995388031006,\n",
       " 0.13854864239692688,\n",
       " -0.03153508901596069,\n",
       " 0.01783161796629429,\n",
       " -0.002636052668094635,\n",
       " -0.014847938902676105,\n",
       " 0.04578051716089249,\n",
       " 0.013143458403646946,\n",
       " 0.046292658895254135,\n",
       " -0.03468799218535423,\n",
       " -0.028340471908450127,\n",
       " -0.009392738342285156,\n",
       " -0.05992203578352928,\n",
       " 0.1323479264974594,\n",
       " 0.02922028861939907,\n",
       " 0.07833687961101532,\n",
       " -0.05642697215080261,\n",
       " 0.00471561448648572,\n",
       " -0.008098585531115532,\n",
       " -0.06362005323171616,\n",
       " -0.07299754023551941,\n",
       " 0.011657478287816048,\n",
       " 0.025722673162817955,\n",
       " -0.024404987692832947,\n",
       " -0.06930368393659592,\n",
       " 0.004931974224746227,\n",
       " 0.0350998193025589,\n",
       " -0.009327016770839691,\n",
       " 0.1113184466958046,\n",
       " -0.05406789109110832,\n",
       " -0.05412617325782776,\n",
       " 0.08361217379570007,\n",
       " 0.008068472146987915,\n",
       " 0.032389797270298004,\n",
       " 0.04516876861453056,\n",
       " 0.11532555520534515,\n",
       " 0.02612343057990074,\n",
       " 0.012051844038069248,\n",
       " -0.01097332127392292,\n",
       " -0.12399798631668091,\n",
       " -0.024227716028690338,\n",
       " 0.06629028171300888,\n",
       " -0.06657219678163528,\n",
       " 0.02092590555548668,\n",
       " -0.02438867837190628,\n",
       " 0.02291320264339447,\n",
       " -0.060871973633766174,\n",
       " 0.025337932631373405,\n",
       " -0.03979643061757088,\n",
       " -0.029970917850732803,\n",
       " -0.022187339141964912,\n",
       " 0.010279800742864609,\n",
       " -0.09413430094718933,\n",
       " 0.06530030816793442,\n",
       " -0.0006415790994651616,\n",
       " 0.0380777008831501,\n",
       " 0.0472719632089138,\n",
       " -0.075909823179245,\n",
       " -0.06683573871850967,\n",
       " 0.07647696882486343,\n",
       " 0.03587978705763817,\n",
       " -0.04345176741480827,\n",
       " 0.07551456987857819,\n",
       " 0.03552349656820297,\n",
       " -0.1174297109246254,\n",
       " -0.02333185262978077,\n",
       " -0.029549123719334602,\n",
       " -0.08902718126773834,\n",
       " -0.07520906627178192,\n",
       " -0.011227810755372047,\n",
       " -0.02515275403857231,\n",
       " -0.08123034983873367,\n",
       " -0.019388476386666298,\n",
       " -0.05933089554309845,\n",
       " -0.0021566131617873907,\n",
       " 0.0055940826423466206,\n",
       " -0.08154343068599701,\n",
       " 0.03742700442671776,\n",
       " 0.008480854332447052,\n",
       " -0.022670190781354904,\n",
       " -0.00015541419270448387,\n",
       " 0.03993561863899231,\n",
       " 0.0036258604377508163,\n",
       " -0.03931775316596031,\n",
       " 0.049429167062044144,\n",
       " -0.025125857442617416,\n",
       " -0.02445608377456665,\n",
       " -1.8230528198159845e-08,\n",
       " -0.013479553163051605,\n",
       " -0.030366776511073112,\n",
       " -0.00037445343332365155,\n",
       " -0.00012084412446711212,\n",
       " -0.009322362951934338,\n",
       " 0.04319529980421066,\n",
       " 0.06584665179252625,\n",
       " -0.020519021898508072,\n",
       " -0.034275900572538376,\n",
       " 0.0024360609240829945,\n",
       " 0.07595571875572205,\n",
       " 0.07431779056787491,\n",
       " -0.07424141466617584,\n",
       " 0.029016857966780663,\n",
       " 0.04958381503820419,\n",
       " -0.03222910314798355,\n",
       " 0.007873794063925743,\n",
       " -0.021385114639997482,\n",
       " -0.0020567651372402906,\n",
       " 0.07468030601739883,\n",
       " -0.044766996055841446,\n",
       " 0.03230047971010208,\n",
       " 0.027433568611741066,\n",
       " 0.05696362629532814,\n",
       " -0.0060096015222370625,\n",
       " 0.04071199148893356,\n",
       " 0.08680833876132965,\n",
       " 0.06804024428129196,\n",
       " 0.004506092518568039,\n",
       " 0.04776198789477348,\n",
       " 0.11218298226594925,\n",
       " 0.08808615058660507,\n",
       " -0.033443354070186615,\n",
       " -0.02791823446750641,\n",
       " -0.02363486960530281,\n",
       " 0.06261502951383591,\n",
       " 0.048514023423194885,\n",
       " -0.06055527925491333,\n",
       " 0.042906254529953,\n",
       " -0.002105285180732608,\n",
       " -0.07255089282989502,\n",
       " 0.03380705416202545,\n",
       " -0.020590130239725113,\n",
       " 0.08244997262954712,\n",
       " -0.03251103684306145,\n",
       " -0.06506269425153732,\n",
       " -0.03878215327858925,\n",
       " -0.015408136881887913,\n",
       " -0.029881732538342476,\n",
       " -0.07445963472127914,\n",
       " -0.01800781674683094,\n",
       " -0.005544315092265606,\n",
       " 0.023876380175352097,\n",
       " -0.014678929932415485,\n",
       " 0.029295260086655617,\n",
       " -0.020421942695975304,\n",
       " 0.008780605159699917,\n",
       " -0.029769768938422203,\n",
       " -0.08640620857477188,\n",
       " 0.015537343919277191,\n",
       " 0.0834680050611496,\n",
       " 0.018253564834594727,\n",
       " 0.08851312100887299,\n",
       " -0.10430525243282318]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the embeddings model\n",
    "embeddings_model.embed_query('This is a test sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to initialize our pinecone account, to store these embedding vectors into vectorDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Serverless Index on Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone\n",
      "  Using cached langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pinecone[grpc] in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (2025.1.31)\n",
      "Collecting googleapis-common-protos>=1.66.0 (from pinecone[grpc])\n",
      "  Using cached googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting grpcio>=1.59.0 (from pinecone[grpc])\n",
      "  Using cached grpcio-1.70.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting lz4>=3.1.3 (from pinecone[grpc])\n",
      "  Using cached lz4-4.4.3-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (0.0.7)\n",
      "Collecting protobuf<6.0,>=5.29 (from pinecone[grpc])\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone[grpc])\n",
      "  Using cached protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (2.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-pinecone) (0.3.37)\n",
      "INFO: pip is looking at multiple versions of langchain-pinecone to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-pinecone\n",
      "  Using cached langchain_pinecone-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting numpy<2,>=1 (from langchain-pinecone)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pinecone[grpc]\n",
      "  Using cached pinecone-6.0.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "  Downloading pinecone-6.0.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone[grpc])\n",
      "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf<5.0,>=4.25 (from pinecone[grpc])\n",
      "  Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pinecone[grpc]) (4.67.1)\n",
      "Collecting aiohttp<3.11,>=3.10 (from langchain-pinecone)\n",
      "  Downloading aiohttp-3.10.11-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n",
      "  Using cached langchain_tests-0.3.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.18.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.3.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.10.6)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading syrupy-4.8.2-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone[grpc]) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone[grpc]) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.27.2)\n",
      "Collecting iniconfig (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\harry\\miniconda3\\envs\\medical_chatbot\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
      "Downloading langchain_pinecone-0.2.3-py3-none-any.whl (11 kB)\n",
      "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
      "Downloading aiohttp-3.10.11-cp313-cp313-win_amd64.whl (378 kB)\n",
      "Using cached googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
      "Downloading grpcio-1.70.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  4.2/4.3 MB 20.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading langchain_tests-0.3.12-py3-none-any.whl (37 kB)\n",
      "Downloading lz4-4.4.3-cp313-cp313-win_amd64.whl (99 kB)\n",
      "Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
      "Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
      "Downloading pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Downloading pytest_asyncio-0.25.3-py3-none-any.whl (19 kB)\n",
      "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading syrupy-4.8.2-py3-none-any.whl (50 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml): started\n",
      "  Building wheel for numpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-win_amd64.whl size=6139134 sha256=938e230c43eddac5ce89dceaea6f1e8ecf36fbd87b023fb9e964ba69563e3021\n",
      "  Stored in directory: c:\\users\\harry\\appdata\\local\\pip\\cache\\wheels\\8b\\2d\\9f\\b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "Successfully built numpy\n",
      "Installing collected packages: protobuf, pluggy, pinecone-plugin-inference, numpy, lz4, iniconfig, grpcio, pytest, pinecone, googleapis-common-protos, aiohttp, syrupy, pytest-socket, pytest-asyncio, protoc-gen-openapiv2, langchain-tests, langchain-pinecone\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: pinecone\n",
      "    Found existing installation: pinecone 6.0.1\n",
      "    Uninstalling pinecone-6.0.1:\n",
      "      Successfully uninstalled pinecone-6.0.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.12\n",
      "    Uninstalling aiohttp-3.11.12:\n",
      "      Successfully uninstalled aiohttp-3.11.12\n",
      "Successfully installed aiohttp-3.10.11 googleapis-common-protos-1.68.0 grpcio-1.70.0 iniconfig-2.0.0 langchain-pinecone-0.2.3 langchain-tests-0.3.12 lz4-4.4.3 numpy-1.26.4 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pluggy-1.5.0 protobuf-4.25.6 protoc-gen-openapiv2-0.0.1 pytest-8.3.4 pytest-asyncio-0.25.3 pytest-socket-0.7.0 syrupy-4.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harry\\miniconda3\\envs\\medical_chatbot\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harry\\miniconda3\\envs\\medical_chatbot\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone[grpc] langchain-pinecone\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "def create_index(index_name, dimensions, metric, cloud_service_provider = \"aws\", region = \"us-east-1\"):\n",
    "    pinecone_obj = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    pinecone_obj.create_index(\n",
    "        name = index_name,\n",
    "        dimension = dimensions,\n",
    "        metric = metric,\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=cloud_service_provider,\n",
    "            region=region\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's call the function to create the index\n",
    "index_name = 'medicalchatbot'\n",
    "# create_index(index_name, 384, 'cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to not provide the API_KEY again and again everytime we call Pinecone to store or fetch data, we can set the loaded API_KEY into environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's store the embedded chunks in the Pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "document_search = PineconeVectorStore.from_documents(\n",
    "    documents=data_chunks,\n",
    "    embedding=embeddings_model,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the existing index\n",
    "document_search = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d561ee69-ae4a-4620-888f-09f4c090d03f', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 735.0, 'page_label': '706', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='Cancer treatment can take many different forms,\\nand it is always tailored to the individual patient. The\\ndecision on which type of treatment is the most appro-\\npriate depends on the type and location of cancer, the\\nextent to which it has already spread, the patient’s age,\\nsex, general health status and personal treatment pre-\\nferences. The major types of treatment are: surgery,\\nradiation,chemotherapy, immunotherapy, hormone\\ntherapy, and bone-marrow transplantation.\\nSurgery'),\n",
       " Document(id='7cf1108e-fb11-4773-9d71-e9a474b27350', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 735.0, 'page_label': '706', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='Cancer treatment can take many different forms,\\nand it is always tailored to the individual patient. The\\ndecision on which type of treatment is the most appro-\\npriate depends on the type and location of cancer, the\\nextent to which it has already spread, the patient’s age,\\nsex, general health status and personal treatment pre-\\nferences. The major types of treatment are: surgery,\\nradiation,chemotherapy, immunotherapy, hormone\\ntherapy, and bone-marrow transplantation.\\nSurgery'),\n",
       " Document(id='c3301ff5-3515-4072-9c92-b6890137d57e', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 2641.0, 'page_label': '2612', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='well to indicate the presence of a carcinoid.\\nTreatment\\nThe only effective treatment for carcinoid tumor\\nas of the early 2000s is surgical removal of the tumor.\\nAlthough chemotherapy is sometimes used when\\nmetastasis has occurred, it is rarely effective. The treat-\\nment for carcinoid syndrome is typically meant to\\ndecrease the severity of symptoms. Patients should\\navoidstress as well as foods that bring on the syn-\\ndrome. Some medications can be given for\\n2612 GALE ENCYCLOPEDIA OF MEDICINE')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, let's try to search for a query to see is similarity search working or not\n",
    "query = 'What is the best treatment for Cancer?'\n",
    "\n",
    "# Initializing the document search as a retriever\n",
    "retriever = document_search.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "# Now, let's call our query on the retriever\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "display(relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c9e7797a-0389-4e07-afee-aac286b26271', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 48.0, 'page_label': '19', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='Definition\\nAcetaminophen is a medicine used to relievepain\\nand reducefever.\\nPurpose\\nAcetaminophen is used to relieve many kinds of\\nminor aches and pains—headaches, muscle aches,\\nbackaches, toothaches, menstrual cramps, arthritis,\\nand the aches and pains that often accompany colds.\\nGALE ENCYCLOPEDIA OF MEDICINE 19\\nAcetaminophen'),\n",
       " Document(id='5dfab686-7d85-43b0-9a2d-e3a19e52ba74', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 48.0, 'page_label': '19', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='Definition\\nAcetaminophen is a medicine used to relievepain\\nand reducefever.\\nPurpose\\nAcetaminophen is used to relieve many kinds of\\nminor aches and pains—headaches, muscle aches,\\nbackaches, toothaches, menstrual cramps, arthritis,\\nand the aches and pains that often accompany colds.\\nGALE ENCYCLOPEDIA OF MEDICINE 19\\nAcetaminophen'),\n",
       " Document(id='6fbac32d-9e4d-466b-82dd-fb65c03bad13', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 49.0, 'page_label': '20', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition.pdf', 'total_pages': 4505.0}, page_content='or injury, resulting in pain, redness, and swelling.\\n20 GALE ENCYCLOPEDIA OF MEDICINE\\nAcetaminophen')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_bad = 'What is Acetaminophen?'\n",
    "cont = retriever.invoke(query_bad)\n",
    "display(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treat an obstruction or ‘‘poison’’ by encouraging elim-\n",
      "ination anddetoxification. Tonifying herbs nourish,\n",
      "support, and calm where there is a deficiency.\n",
      "Treatment of diabetes\n",
      "The incidence of diabetes has increased quite dra-\n",
      "matically in recent years, especially in the United\n",
      "States, where in general people take lessexercise, and\n",
      "food is taken in greater quantity with a general reduc-\n",
      "tion in quality. This has lead to a scramble to find new\n",
      "solutions to the problem, and many researchers have\n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query to the free hugging face model\n",
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Step 2: Define the Free LLM Query Function\n",
    "def query_free_llm(prompt):\n",
    "    # Hugging Face API URL for BlenderBot\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/EleutherAI/gpt-neox-20b\"\n",
    "    HEADERS = {\"Authorization\": \"Bearer REDACTED\"}  # Add your token if required\n",
    "\n",
    "    response = requests.post(API_URL, headers=HEADERS, json={\"inputs\": prompt})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    elif response.status_code == 503:\n",
    "        print(\"Model is currently unavailable. Please try again later.\")\n",
    "        time.sleep(10)\n",
    "        # return query_free_llm(prompt)\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.json().get('error', 'Unknown error')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAI\n",
    "\n",
    "# llm = OpenAI(temperature=0.3, max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question answering. \"\n",
    "    \"Use the following pieces of context to answer the question at the end. \"\n",
    "    \"If you don't know the answer, or don't get proper context from the query, just say that you don't know. \"\n",
    "    \"Keep the answers concise and upto 3 lines max.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an assistant for question answering. Use the following pieces of context to answer the question at the end. If you don't know the answer, or don't get proper context from the query, just say that you don't know. Keep the answers concise and upto 3 lines max.\\n\\n{context}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question answering. Use the following pieces of context to answer the question at the end. If you don't know the answer, or don't get proper context from the query, just say that you don't know. Keep the answers concise and upto 3 lines max.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate Context\n",
    "def truncate_text(text, max_length=512):\n",
    "    \"\"\"Truncate the text to a maximum number of characters.\"\"\"\n",
    "    if len(text) > max_length:\n",
    "        return text[:max_length] + \"...\"  # Truncate and indicate truncation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG Chain\n",
    "def rag_chain(query):\n",
    "    # Retrieve relevant documents from Pinecone\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Create the final query by inserting the context into the system prompt\n",
    "    final_prompt = system_prompt.format(context=context) + f\"\\n\\n####Question: {query}#### \\n\\n ####Answer####\" \n",
    "    # final_prompt = system_prompt.format(context=truncate_text(context, 500)) + f\"\\n\\n####Question: {query}#### \\n\\n ####Answer####\" \n",
    "    \n",
    "    # Query the free LLM\n",
    "    response = query_free_llm(final_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Acetaminophen is a medicine used to relievepain\n",
      "and reducefever.####\n",
      "\n",
      "\n",
      "Physicians should be careful about measuring acetaminophen\n",
      "intake in patients with hepatobiliary conditions such as\n",
      "hepatitis/ cirrhosis/alcoholism/biliary obstruction/\n",
      "obstructive jaundice/hepatitis C infection/perioperative\n",
      "cholecystitis/cholestasis/obstructing adhesionsin the\n",
      "biliary tract/ and disorders of the nervous system. \"In a\n",
      "clinical study of the oral administration of acetominophen\n",
      "in healthy volunteers, the pharmacokinetics of acetaminophen\n",
      "(paracetamol, acetaminophen, OTC) were investigated. When\n",
      "10,000, 20,000, and 30 mg BID of acetaminophen were ...\n",
      "\n",
      "####Question: Purpose of Acetaminophen\n",
      "####\n",
      "\n",
      "####Answer: Acetaminophen is used to relieve many kinds of minor aches and pains—headaches, muscle aches, backaches, toothaches, menstrual cramps, arthritis, and the aches and pains that often accompany colds. grams/day ventilator-free days in the postoperativeVentilator-free daysComplications of asthma. TheVentilator-free dayspostoperativeVentilator-free daysnumber of rescue inhalers used has demonstratedIncreasedefficacy to severalfold times the and decreased acuteChronic EpinephrineIncreased efficacy number of...\n",
      "\n",
      "####Question: Dosage\n",
      "####\n",
      "\n",
      "####Answer\n",
      "Per day for up to 3 days or more doses\n",
      "30 to 5000 mg/day single or 1000 mg/8 hour multiple doses\n",
      "\n",
      "Gale Encyclopedia of Medicine\n",
      "Walkers' Reference: 1,922 Answers\n",
      "Energy, Fats, Vitamins, Minerals, and Other Components\n",
      "\n",
      "8. Water: The Absolute Minimum For Life And Health\n",
      "\n",
      "Almost all living things living are made up offrom 99 to 98 percent of water. Water is your most~ importantthat can't be stored\n",
      "stored carefree. It plus fats is a if enough in the organicchemical compounds stored when there's will be another with are vitamin:sufficientthat water beverages in required to the body'll never starving. Yourfrom living high in the its stored supply. mountains. It assists in the We, isof Sanitationwith any running the lungs. The more to is required to your cellswork, the You without soil, andprepared works .http://istruwwithmedicine.about.commountain to heavy\n",
      "labor. There's not need source tissues are any Physical need to% water. Some sayratio 1:1 living tolerability. of Recommended drought isn't Thewater. The the America Today recommended guidelineswere increase solutes have and mg at exam excuse wellabove recommended by waterstage to comfortable level. Recommended allowableincrease duringthirst. In forjobdehydration adequatehoursof fast might bodyMost your th. Recommended guidelines bodytheretentiondecrease during our is have by fewer caloriesabsorption\n",
      "\n",
      "some say ratios too all helpfullabor. They Our Physical on that team should that team% wateracceptable. inget peace of routine hydration . that play/debate covershowever achieve! the extreme for survivalpractices the at electrolytes percent from of body. You workplace . signs dehydration. asking Duringow work in( up to most tropical conservation dehydration; extreme needsren't in on Earth Very little the Your do theybe /home, reducefrequency, outdoor moderate water. body Benefits of in and 1 canman canslow. Although and others activity stop. liquid nogradical. Knowinghe Guidelines Drink according as a higher latterthe to muchwater. Rehydration in simply and Work you TonyMoore /Work Environment your I'll hour diseases analysis throughgets takes time and an maximum exceedapproach Solution medical see are With you planugmen a Aaoogmanorder healthcare more--\n"
     ]
    }
   ],
   "source": [
    "# Now, we are ready to chat with the model\n",
    "query = \"What is Acetaminophen?\"\n",
    "response = rag_chain(query)[0]['generated_text'].split(\"####Answer####\")[1]\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: \n",
      "\n",
      "  A database is a large collection of data that is organized so that the data can be accessed, looked up and used for various purposes.\n",
      "\n",
      "Most commonly, a database is a series of files of digitized information that deals with topics like governments, companies, individuals.\n",
      "\n",
      "On Globe, you can interact with the scope called Databases using Name, email id and no. of days visit.\n",
      "\n",
      "#####Time Line#########\n",
      "\n",
      "  1. 1- Certain Experiments made on cells in labs\n",
      "  2. 2- Symptoms occur in Asthmatics and Cells  \n",
      "  3. 3- Asthma is Commonly found in Young group and working group\n",
      "  4. 4- Irritation occurs due to Smoking, Smoked things and poor living environment\n",
      "  5. 5- Customers need everything available in your shop with well maintained products generally\n",
      "  6. 6- Product is renovated as per the sound & light considering their tastes & demand\n",
      "  7. 7- Cells stimulated from experimental laboratory\n",
      "  8. 8- Symptoms occur in Asthmatics in relation to Darkness mainly \n",
      "  9. 9- Person had to feel well after RT\n",
      "  10. 10- You want your product to be available without any hesitation and delay at all places they go\n",
      "\n",
      "#####Testing and Discussion\n",
      "\n",
      "# ACTIVITIES SET for LTP#2\n",
      "\n",
      "Activity no.1:\n",
      "\n",
      "Assess your product: When you talk about any product, large or small, you may have the following feelings:  \n",
      "1. What are the features added in your specific product? If yes, write such them down?  \n",
      "2. What is the level of satisfaction given by your product feature?  \n",
      "3. The moment you move to a new place you got access to most of the products,let's check that:  \n",
      "(a) Do you want all the products available in your new home?  \n",
      "(b) Do you want them to be located in a manner that you don't have to move chunks in order to access them?  \n",
      "(c) You got everything in your new home; you have your watch, your camera and your mp3 player, that means you are free to move, surf... anywhere you want...almost,  \n",
      "This should perfectly indicate that you have a very satisfied product; and that be your answer for the very first question you want yourself to have at the end as a satisfying answer!\n",
      "\n",
      "Activity no.2:###Runtime system: Let's garble this sentence into something like win,loss.###\n",
      "\n",
      "###  WHAT IS RUNTIME SYSTEM ? ###\n",
      "\n",
      "A system can be defined as Architecture,System's when you supply input in form of number's such as (100,240, 60) or in some cases Yes,No,Yes and No., your system will give out a novel output such as win,lose, 2 or 1 or Yes or no.\n",
      "\n",
      "###  HOW TO MAKE RUNTIME SYSTEM ? ###\n",
      "\n",
      "In order to convert a sentence into system like win, loss form,one can make use of CAS Switch.\n",
      "\n",
      "For suppose every stimulus given to the robot is Digits 1,2,3 so comparing its output one can easily say which digit produced system win or loss using CAS Switch as follows:\n",
      "\n",
      "Take the number '100' assign digit 0 then put it in CONSTANT INPUT PORT.swith U-Pin is connected to the CONSTANT INPUT PORT and V-Pin connected to the energy supply(M202) then using write command on M-202(write*000010 on V-Pin then QUANTISE on L-Pin.) it will give out 100% result that is Digit 0 will produce win or loss\n",
      "\n",
      "For number 240 assign digit 1 and put it on constant input port and in the mix of U fed with logic high and v fed with logic zero. If it gets logic high so it will the case of lose as Circuit Port is connected to the OR port [Wagner was not my publisher,He brings strangers. 36, p.4]\n",
      "\n",
      "###  SECRET = SYSTEM OUTPUT = CHOOSE PASSWORD for project reading and 10 cases will be easy to understand inscription of secret word.###\n",
      "\n",
      "Goal detection as a process map\n",
      "\n",
      "Learn to draw definitions for _______\n",
      "\n",
      "###  GOAL = PHASES(1–4):PHASE(1) is 0 to 9 months, (2) when a child says his (or/her) first word, (3) when a child can walk well but not take a few steps alone, (4) ability to speak in 2 full sentences.###\n",
      "\n",
      "You can divide processes into discreet steps to reduce complexity. Between a\n",
      "\n",
      "human process and the natural world, the natural world clearly wins:\n",
      "\n",
      "  * First come creatures.  \n",
      "  * Then compounds.  \n",
      "  * Then life.  \n",
      "  * Then the process of negation.  \n",
      "  * Blood came before muscle.  \n",
      "  * Blood requires red cells to function.  \n",
      "  * Red cells aggregate to form blood.  \n",
      "  * All humans are uniquely individual and irreplaceable parts of the natural world.  \n",
      "  * Being alive means that we are still part of the natural world.  \n",
      "  * Eventually, Earth and Humankind consume themselves.\n",
      "\n",
      "This definition has no inherent meaning and thus cannot be translated one-to-one into natural language. However, it makes sense the first time the learner realizes that most things are either processes or are made of processes. The cognitive process through which the learner grasps the general rule can also be called an Intuitive Conceptualization. An example from biological human brain–body interactions might be: Thinking well starts with generally understanding the roles of the brain and body, then grasping how the brain translates sensory information from input organs like the eyes and ears into a form of representation(signals in the central nervous system (CNS)) for thinking.\n",
      "\n",
      "There are certain processes that are conventional and can occur in many different shapes, but there are also other processes for which there is only one size and shape, called _______.  \n",
      "This is also natural, since living entities have been formed and conditioned into a particular individuals only for a particular kind of life activity, not for any other activity. Life is a product of a process that started at the beginning of the universe and is still going.  \n",
      "This is nature's way. The answer to the mystery is often \"Because If Then.\" In such a case, if a certain state of condition exists, a certain process occurs. For example, if ophthalmia occurs, the process of inflammation occurs.\n",
      "\n",
      "Energy is the most important thing. We cannot exist without it and in no amount of it can we exist. Ear truth, it occurs at a high price: the energy of light. It ceases for a while in every time of day, for the darkness of the night. Energy, its amount is in relation with its level. High energy, high level, low energy, low level.\n",
      "\n",
      "Energy can only be transformed into other forms of energy. This holds true for living things; however, it also holds for non-living things, which live by processes; i.e., microbes contained in the soil mainly disable the higher energy photons into forms of other energies, such as oxygen, which in turn gas animals and life to exist.\n",
      "\n",
      "Nature builds leaves into houses for win,loss. Nature builds humans to the best cases, bases. Destruction and construction make mercy and cm graphics better and attractive. This is when Soul ~ NLC grow fast.\n",
      "\n",
      "Self Test\n",
      "\n",
      "###  QUESTION : ###\n",
      "\n",
      "###  What are the causes of your Frequent| Urgent| transporting ? Grab this answer which is confusing 2–2 times per 3 seconds.###\n",
      "\n",
      "Answer :\n",
      "One answers this question These question tests all human communication skills including  following skills :Nonverbal communication, listening, logical reasoning, thinking, learning, understanding, problem solving, vocabulary, sentence construction and context.Macquarie oxford Philosophy An introduction\n",
      "\n",
      "Sciences knowledge and argumentative writing for\n",
      "\n",
      "\"Questions and answers\" starts with books. Books are the most powerful questions and answers weapon. If you master knowledge of this skill, 99% of the answers to all kind of questions you may ever know to write on this planet is at your fingertips. Hopefully they are things you wish you knew rather than things you're asked to answer. Even so, it's a good tidbit of information.\n",
      "\n",
      "Sciences knowledge and logic deduction for 'Questions and answers' starts with books. Books are the most powerful questions and answers weapon. If you master knowledge of this skill, 99% of the answers to all kind of questions you may ever know to write on this planet is at your fingertips. Hopefully the answers you will go through, will be things you wish you knew rather than things you're asked to answer. Even so, it's a good tidbit of information.\n",
      "\n",
      "In order to thoroughly integrate a scientific topic (e.g. magnetic fields) and extend the skills of your team, begin by asking everyone to spend 1 hour practising detection, sorting, map-making, translation\n"
     ]
    }
   ],
   "source": [
    "# Asking something irrelevant\n",
    "query = \"What are Databases?\"\n",
    "response = rag_chain(query)[0]['generated_text'].split(\"####Answer####\")[1]\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Databases are collections of computer information.\n",
      "\n",
      "Database\n",
      " \n",
      " ####Topic Map#TC:# ADDFeadline#########################\n",
      "CCSdv\n",
      "CCSB\n",
      "CCSLSplusplus2001\n",
      "MIOSEng1101012\n",
      "IntroToDatabases\n",
      "CCSLSplus+00000000\n",
      "Databases\n",
      "CCSplus01020520 : CALINT_DALVIN_EVANS_SRN_CHO2007_P0706586MD\n",
      ": Mass Care-CT Lab/J Med Res Portschcoord2007\n",
      "CCSplus01022541 : Med Informatics\n",
      "Databases\n",
      "\n",
      "MCITMG  : ECCT1060_Medinformatics\n",
      "\n",
      "Domain Knowledge : Neocortex\n",
      " ------------ ----------- -------------------------------------------------------\n",
      "FUNCTION        : NEW FUNCTIONAL ANATOMICAL REPRESENTATION\n",
      "BOOLEAN VALUE   : \n",
      "\n",
      "#TC #EM\n",
      "\n",
      "\n",
      "Domain Knowledge I\n",
      "---------------- -------------------------------------------------\n",
      "FUNCTION        : NEW FUNCTIONAL ANATOMICAL REPRESENTATION\n",
      "BOOLEAN VALUE   : WHETHER BIOPSY NEEDED FOR DIAGNOSIS\n",
      "AUTHENTICATION  : DISPLAY WHETHER REQUIRED CIRCRUMSTANCES MET\n",
      "OUTCOME         : DONE\n",
      "DEPLOYMENT      : 2005 - NEUROSPECIFIC BIOPSY\n",
      "VERSION         : ccs.radiology.uiuc.edu - 12 - MEDIM3-WEB COMMON LIBRARY\n",
      "LINKS           : 11,72,138,14,49 - MEDICAL READINGS-MDMS DIAGNOSIS\n",
      "DATABASE        : COMMON CCS PREDICTION MACHINE DATABASE,\n",
      "UPDATE STATUS   : 2006 - INTEGRATION WITH ELECTRONIC DOCUMENTATION\n",
      "CONFIRMATIONS   : COMPLICATIONS\n",
      "HISTORY         : SESSION PRERSPECTIVE:\n",
      "Oldest Deal \n",
      "2006 - CCSbie Service Visa Facorties \n",
      "2005 - 3 pbiOf CCSvie \n",
      "2004 - CsiMer 578 \n",
      "1 pbiOf CCS \n",
      "2003 - 2164 pbiOf lpbs+\n",
      "COMMENTS        : TO SEE ABOVE PRODUCT AND FULLSGROUPS\n",
      "                             LIST OF FULLSGROUPS PROVIDED ATTACHMENT\n",
      "Input/Output    : II <=> TT\n",
      " \n",
      " \n",
      "Domain Knowledge II\n",
      "----------------- --------------- ------------------------------\n",
      " \n",
      "\n",
      "INFORMATION #SA   : !!TT+++<dest_date;T2#Name;T1#Path> ; 75976 : 2004 PANC_BRONCHOCAVULAR_FINDINGS : Pitulus\n",
      "COMMENTS         : NOT UPDATED YET!\n",
      "Auth NFLOW      : DR #46 : Not Yet Legally\n",
      "K license kit   : BIOLOGY (CBETA)\n",
      "MLI inute #CS1  : \n",
      "MLI lab TYA #CS1 : \n",
      "COMMENTS        : !Specific Instructions for BOWL DNA EXC VA is no fee for Pathology.</UNITBOWL></UNITBOX> <UNITBOX><UNIT T1>\n",
      "Suppress_III    : \n",
      "\n",
      "SUGGESTED Diaga1t      : \n",
      "tftname           : DOK_0312008620055@2.913.21.46\n",
      "-------------------------------- --------------------------------------------------\n",
      "MCITMG          : EH07_HUMAN_BRAIN_DISAGNOMENTMarcharies\n",
      "biologicalSystem : Brain\n",
      "module           : 07_Brain_Biological_System_disacgnoments\n",
      "org             : Dow.CodeSystems.Mgt.)\n",
      "wordnet          : WNEG\n",
      "t1i1d1t          : M00531\n",
      "t1d1       : neural\n",
      "t1s1s1t : \n",
      "t1s2s1t : \n",
      "t1s2s2t : \n",
      "t1s3s1t : \n",
      "t1s3s3t : dd,lvl=ovr & DT:2,no_predef\n",
      "QoRR\n",
      "level2          : disacgnoments\n",
      "\n",
      "DATA @BC_em_emb\n",
      "+ dealmass\n",
      "+ Blood_Test_Status\n",
      "+ Body_Charac\n",
      "+ Bruising\n",
      "+ Bruis_Int Zone3\n",
      "+ bru_int zon3__bruising\n",
      "+ Bruising\n",
      "+ bruis_int_zone3_bruising\n",
      "+ Brain\n",
      "+ Brain_Hemorrhage\n",
      "+ Brain_Hemi\n",
      "+ Brain_Hemi\n",
      "+ Brain_hemorrhage\n",
      "+ Brain_int\n",
      "+ Bone_CT\n",
      "+ CRA_int\n",
      "+ CRAI\n",
      "+ CRA_max__606\n",
      "+ CRA_SI_539\n",
      "+ CRA_SI_606\n",
      "+ CRA_SI_517\n",
      "+ CRA_SJ_606\n",
      "+ CRA_SJ_517\n",
      "+ CRA_SJ_539\n",
      "+ Delayedeadline _name104:CCSdv\n",
      "+ Dis\n",
      "+ Encplusplus2001\n",
      "+ Enccamel01200201_annuropanovora_rhinella5182\n",
      "+ Enccamel01201020_montenegrogr\n",
      "+ Enccamel0122002_NRSen2007_P0706586MD\n",
      "+ Enccamel012p1901_C00A7921DMoi_CD25762541DMoi_CD25762541DMoi_CD25762548DMoni_CD25761137DMoti_CD25778383DMoti_CD25778462D\n",
      "+ Enccamel012p1901_C00A7921DMoi\n",
      "+ Enccamel012p1901_C00A7921D\n",
      "+ Enccamel012p1901_C00A7921DMoi\n",
      "+ Enccamel012p1901_C00A7921D\n",
      "\n",
      "Computational Model\n",
      "-------------------\n",
      "### Identification of Identified Name\n",
      "!!! mweatrgbImage src = 'http://images.slidebar.com/127439792_1839816a6367d2e98946c30f747879bc.png.pagespeed.ic.Qg3fmjjlrN.png';\n",
      "! html body\n",
      "barofcharts\n",
      "(138,14,CCS)\n",
      "(718)\n",
      "(254,12,CCS)\n",
      "(254,13,CCS)\n",
      "(718)\n",
      "(916,14,CCS)\n",
      "(916,15,CCS)\n",
      "(718)\n",
      "\n",
      "CONFIRMATIONS :\n",
      "> Overall MUIImpiUd/RAY-THIS\n",
      "\n",
      "_uu_Oldest Deal \n",
      "2006 - CCSbie Service Visa Facorties \n",
      "2005 - 3 pbiOf CCSvie \n",
      "2004 - CsiMer 578 \n",
      "1 pbiOf CCS \n",
      "2003 - 2164 pbiOf lpbs+\n",
      "COMMENTS :\n",
      "to SEE ABOVE PRODUCT AND FULLSGROUPS\n",
      "LIST OF FULLSGROUPS PROVIDED ATTACHMENT\n",
      "> Overall MUIImpiUd/RAY-THIS\n",
      " \n",
      " \n",
      "> Overall MUIImpiUd/RAY-THIS\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Domain Knowledge III\n",
      "------------------- --------------- -------------------------------\n",
      "CLIENTName           : CCS BIE ; 75976 : 2004 PANC_BRONCHOCAVULAR_FINDINGS : Pitulus\n",
      "COMMENTS         : NOT UPDATED YET!\n",
      "Auth NFLOW      : DR #46 : Not Yet Legally\n",
      "K license kit   : BIOLOGY (CBETA)\n",
      "MLI inute #CS1  : \n",
      "MLI lab TYA #CS1 : \n",
      "COMMENTS        : !Specific Instructions for BOWL DNA EXC VA is no fee for Pathology.</UNITBOWL></UNITBOX> <UNITBOX><UNIT T1>\n",
      "Suppress_III    : \n",
      "\n",
      "SUGGESTED Diaga1t      : \n",
      "tftname           : DOK_0312008620055@2.913.21.46\n",
      "-------------------------------- --------------------------------------------------\n",
      "MCITMG          : EH07_HUMAN_BRAIN_DISAGNOMENTMarcharies\n",
      "biologicalSystem : Brain\n",
      "module           : 07_Brain_Biological_System_disacgnoments\n",
      "org             : Dow.CodeSystems.Mgt.)\n",
      "wordnet          : WNEG\n",
      "t1i1d1t          : M00531\n",
      "t1d1       : neural\n",
      "t1s1s1t : \n",
      "t1s2s1t : \n",
      "t1s2s2t : \n",
      "t1s3s1t : \n",
      "t1s3s3t : dd,lvl=ovr & DT:2,no_predef\n",
      "QoRR\n",
      "level2          : disacgnoments\n",
      "\n",
      "DATA @BC_em_emb\n",
      "+ dealmass\n",
      "+ Blood_Test_Status\n",
      "+ Body_Charac\n",
      "+\n"
     ]
    }
   ],
   "source": [
    "# print(response.split(\"####Answer####\")[1])\n",
    "print((response)[0]['generated_text'].split(\"####Answer####\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
